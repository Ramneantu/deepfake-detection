% Use this as your main bibliography file.

@misc{DF_vice,
  title = {Deepfakes Were Created As a Way to Own Women's Bodiesâ€”We Can't Forget That},
  howpublished = {\url{https://www.vice.com/en/article/nekqmd/deepfake-porn-origins-sexism-reddit-v25n2}},
  note = {Accessed: 2021-08-06}
}

@misc{nguyen2021deep,
      title={Deep Learning for Deepfakes Creation and Detection: A Survey}, 
      author={Thanh Thi Nguyen and Quoc Viet Hung Nguyen and Cuong M. Nguyen and Dung Nguyen and Duc Thanh Nguyen and Saeid Nahavandi},
      year={2021},
      eprint={1909.11573},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{karras2020analyzing,
      title={Analyzing and Improving the Image Quality of StyleGAN}, 
      author={Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
      year={2020},
      eprint={1912.04958},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{li2020face,
      title={Face X-ray for More General Face Forgery Detection}, 
      author={Lingzhi Li and Jianmin Bao and Ting Zhang and Hao Yang and Dong Chen and Fang Wen and Baining Guo},
      year={2020},
      eprint={1912.13458},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{roessler2019faceforensics++,
	author = {Andreas R\"ossler and Davide Cozzolino and Luisa Verdoliva and Christian Riess and Justus Thies and Matthias Nie{\ss}ner},
	title = {FaceForensics++: Learning to Detect Manipulated Facial Images},
	booktitle = {ICCV 2019},
	year={2019}
}

@misc{durall2020unmasking,
      title={Unmasking DeepFakes with simple Features}, 
      author={Ricard Durall and Margret Keuper and Franz-Josef Pfreundt and Janis Keuper},
      year={2020},
      eprint={1911.00686},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@INPROCEEDINGS{anomalyPaper,
  author={Khodabakhsh, Ali and Busch, Christoph},
  booktitle={2020 International Conference of the Biometrics Special Interest Group (BIOSIG)}, 
  title={A Generalizable Deepfake Detector based on Neural Conditional Distribution Modelling}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  doi={}}
  
@misc{Mirsky2021,
abstract = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these "deepfakes"have advanced significantly. In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
archivePrefix = {arXiv},
arxivId = {2004.11138},
author = {Mirsky, Yisroel and Lee, Wenke},
booktitle = {ACM Computing Surveys},
doi = {10.1145/3425780},
eprint = {2004.11138},
file = {:Users/emrekavak/Library/Application Support/Mendeley Desktop/Downloaded/Mirsky, Lee - 2020 - The Creation and Detection of Deepfakes A Survey(2).pdf:pdf},
issn = {15577341},
keywords = {Deepfake,deep fake,face swap,generative AI,impersonation,reenactment,replacement,social engineering},
month = {apr},
number = {1},
publisher = {Association for Computing Machinery},
title = {{The Creation and Detection of Deepfakes}},
url = {https://arxiv.org/abs/2004.11138v3},
volume = {54},
year = {2021}
}
@article{Tolosana2020,
abstract = {The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.},
archivePrefix = {arXiv},
arxivId = {2001.00179},
author = {Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
doi = {10.1016/j.inffus.2020.06.014},
eprint = {2001.00179},
file = {:Users/emrekavak/Library/Application Support/Mendeley Desktop/Downloaded/Tolosana et al. - 2020 - DeepFakes and Beyond A Survey of Face Manipulation and Fake Detection.pdf:pdf},
issn = {15662535},
journal = {Information Fusion},
keywords = {Benchmark,Databases,Deepfakes,Face manipulation,Face recognition,Fake news,Media forensics},
month = {jan},
pages = {131--148},
publisher = {Elsevier B.V.},
title = {{Deepfakes and beyond: A Survey of face manipulation and fake detection}},
url = {https://arxiv.org/abs/2001.00179v3},
volume = {64},
year = {2020}
}

@article{Cozzolino2018,
abstract = {Distinguishing manipulated from real images is becoming increasingly difficult as new sophisticated image forgery approaches come out by the day. Naive classification approaches based on Convolutional Neural Networks (CNNs) show excellent performance in detecting image manipulations when they are trained on a specific forgery method. However, on examples from unseen manipulation approaches, their performance drops significantly. To address this limitation in transferability, we introduce Forensic-Transfer (FT). We devise a learning-based forensic detector which adapts well to new domains, i.e., novel manipulation methods and can handle scenarios where only a handful of fake examples are available during training. To this end, we learn a forensic embedding based on a novel autoencoder-based architecture that can be used to distinguish between real and fake imagery. The learned embedding acts as a form of anomaly detector; namely, an image manipulated from an unseen method will be detected as fake provided it maps sufficiently far away from the cluster of real images. Comparing to prior works, FT shows significant improvements in transferability, which we demonstrate in a series of experiments on cutting-edge benchmarks. For instance, on unseen examples, we achieve up to 85% in terms of accuracy, and with only a handful of seen examples, our performance already reaches around 95%.},
archivePrefix = {arXiv},
arxivId = {1812.02510},
author = {Cozzolino, Davide and Thies, Justus and R{\"{o}}ssler, Andreas and Riess, Christian and Nie{\ss}ner, Matthias and Verdoliva, Luisa},
eprint = {1812.02510},
file = {:Users/emrekavak/Library/Application Support/Mendeley Desktop/Downloaded/Cozzolino et al. - 2018 - ForensicTransfer Weakly-supervised Domain Adaptation for Forgery Detection.pdf:pdf},
month = {dec},
title = {{ForensicTransfer: Weakly-supervised Domain Adaptation for Forgery Detection}},
url = {https://arxiv.org/abs/1812.02510v2 http://arxiv.org/abs/1812.02510},
year = {2018}
}
@article{Aneja2020,
abstract = {We propose Deep Distribution Transfer(DDT), a new transfer learning approach to address the problem of zero and few-shot transfer in the context of facial forgery detection. We examine how well a model (pre-)trained with one forgery creation method generalizes towards a previously unseen manipulation technique or different dataset. To facilitate this transfer, we introduce a new mixture model-based loss formulation that learns a multi-modal distribution, with modes corresponding to class categories of the underlying data of the source forgery method. Our core idea is to first pre-train an encoder neural network, which maps each mode of this distribution to the respective class labels, i.e., real or fake images in the source domain by minimizing wasserstein distance between them. In order to transfer this model to a new domain, we associate a few target samples with one of the previously trained modes. In addition, we propose a spatial mixup augmentation strategy that further helps generalization across domains. We find this learning strategy to be surprisingly effective at domain transfer compared to a traditional classification or even state-of-the-art domain adaptation/few-shot learning methods. For instance, compared to the best baseline, our method improves the classification accuracy by 4.88% for zero-shot and by 8.38% for the few-shot case transferred from the FaceForensics++ to Dessa dataset.},
archivePrefix = {arXiv},
arxivId = {2006.11863},
author = {Aneja, Shivangi and Nie{\ss}ner, Matthias},
eprint = {2006.11863},
file = {:Users/emrekavak/Library/Application Support/Mendeley Desktop/Downloaded/Aneja, Nie{\ss}ner - 2020 - Generalized Zero and Few-Shot Transfer for Facial Forgery Detection.pdf:pdf},
issn = {2331-8422},
month = {jun},
title = {{Generalized Zero and Few-Shot Transfer for Facial Forgery Detection}},
url = {https://arxiv.org/abs/2006.11863v1 http://arxiv.org/abs/2006.11863},
year = {2020}
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4401--4410},
  year={2019}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@Article{dlib09,
  author = {Davis E. King},
  title = {Dlib-ml: A Machine Learning Toolkit},
  journal = {Journal of Machine Learning Research},
  year = {2009},
  volume = {10},
  pages = {1755-1758},
}

@misc{swap,
  title = {{Deepfakes} github},
  howpublished = {\url{https://github.com/deepfakes/faceswap}},
}